{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355529d7-7b42-4134-b184-09d870d6f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import mlflow\n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e2c97a-2a56-417a-9e05-d80b51cca0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "cancelled_flights = pd.read_csv(\"/home/cdsw/data/preprocessed_flight_data.csv\")\n",
    "cancelled_flights = cancelled_flights.dropna()\n",
    "\n",
    "# select features and target\n",
    "X = cancelled_flights[\n",
    "    [\n",
    "        \"uniquecarrier\",\n",
    "        \"origin\",\n",
    "        \"dest\",\n",
    "        \"week\",\n",
    "        \"hour\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "y = cancelled_flights[[\"cancelled\"]]\n",
    "\n",
    "# one-hot encode categorical columns\n",
    "categorical_cols = [\"uniquecarrier\", \"origin\", \"dest\"]\n",
    "ct = ColumnTransformer(\n",
    "    [(\"le\", OneHotEncoder(), categorical_cols)], remainder=\"passthrough\"\n",
    ")\n",
    "X_trans = ct.fit_transform(X)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23bc784a-3e0e-45ab-868f-4588ff831348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /home/cdsw/.local/lib/python3.7/site-packages (0.2.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied: py4j in /usr/local/lib/python3.7/site-packages (from hyperopt) (0.10.9.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/cdsw/.local/lib/python3.7/site-packages (from hyperopt) (2.6.3)\n",
      "Requirement already satisfied: future in /home/cdsw/.local/lib/python3.7/site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: tqdm in /home/cdsw/.local/lib/python3.7/site-packages (from hyperopt) (4.64.1)\n",
      "Requirement already satisfied: scipy in /home/cdsw/.local/lib/python3.7/site-packages (from hyperopt) (1.7.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from hyperopt) (1.19.4)\n",
      "Requirement already satisfied: cloudpickle in /runtime-addons/cmladdon-2.0.36-b121/opt/cmladdons/python/site-packages (from hyperopt) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "# we install the Hyperopt package for our experiments. \n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f3d225-c5d4-48bb-a995-5ad40053b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "#hyperparameter tuning\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b0de11-094f-431d-ab86-1885dc896fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>uniquecarrier</th>\n",
       "      <th>flightnum</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>crsdeptime</th>\n",
       "      <th>crsarrtime</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>crselapsedtime</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-09-14</td>\n",
       "      <td>US</td>\n",
       "      <td>1628</td>\n",
       "      <td>ROC</td>\n",
       "      <td>PIT</td>\n",
       "      <td>715</td>\n",
       "      <td>820</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>7</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-09-15</td>\n",
       "      <td>US</td>\n",
       "      <td>1628</td>\n",
       "      <td>ROC</td>\n",
       "      <td>PIT</td>\n",
       "      <td>715</td>\n",
       "      <td>820</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>7</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-09-16</td>\n",
       "      <td>US</td>\n",
       "      <td>1628</td>\n",
       "      <td>ROC</td>\n",
       "      <td>PIT</td>\n",
       "      <td>715</td>\n",
       "      <td>820</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>7</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>US</td>\n",
       "      <td>2608</td>\n",
       "      <td>BDL</td>\n",
       "      <td>PBI</td>\n",
       "      <td>700</td>\n",
       "      <td>1011</td>\n",
       "      <td>1</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>CO</td>\n",
       "      <td>1173</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1345</td>\n",
       "      <td>1519</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>13</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date uniquecarrier  flightnum origin dest  crsdeptime  crsarrtime  \\\n",
       "0  2010-09-14            US       1628    ROC  PIT         715         820   \n",
       "1  2010-09-15            US       1628    ROC  PIT         715         820   \n",
       "2  2010-09-16            US       1628    ROC  PIT         715         820   \n",
       "3  2010-02-06            US       2608    BDL  PBI         700        1011   \n",
       "4  2010-08-31            CO       1173    EWR  ORD        1345        1519   \n",
       "\n",
       "   cancelled  crselapsedtime  distance  hour  week  \n",
       "0          1            65.0     224.0     7  37.0  \n",
       "1          1            65.0     224.0     7  37.0  \n",
       "2          1            65.0     224.0     7  37.0  \n",
       "3          1           191.0    1133.0     7   5.0  \n",
       "4          1           154.0     719.0    13  35.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#this is the Flights Dataset the Label is cancelled : 1(True) or 0 (false)\n",
    "cancelled_flights.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb1cd6e-2a79-4eaa-8236-4ba9e0e751fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fl_date           6360634\n",
       "uniquecarrier     6360634\n",
       "flightnum         6360634\n",
       "origin            6360634\n",
       "dest              6360634\n",
       "crsdeptime        6360634\n",
       "crsarrtime        6360634\n",
       "cancelled         6360634\n",
       "crselapsedtime    6360634\n",
       "distance          6360634\n",
       "hour              6360634\n",
       "week              6360634\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dealing with about 6 Million Records here. \n",
    "cancelled_flights.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f7139eb-4ae1-42da-a096-06c59c793a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': ['binary:logistic'],\n",
       " 'use_label_encoder': [False],\n",
       " 'base_score': [None],\n",
       " 'booster': [None],\n",
       " 'callbacks': [None],\n",
       " 'colsample_bylevel': [None],\n",
       " 'colsample_bynode': [None],\n",
       " 'colsample_bytree': [None],\n",
       " 'early_stopping_rounds': [None],\n",
       " 'enable_categorical': [False],\n",
       " 'eval_metric': [None],\n",
       " 'gamma': [None],\n",
       " 'gpu_id': [None],\n",
       " 'grow_policy': [None],\n",
       " 'importance_type': [None],\n",
       " 'interaction_constraints': [None],\n",
       " 'learning_rate': [None],\n",
       " 'max_bin': [None],\n",
       " 'max_cat_to_onehot': [None],\n",
       " 'max_delta_step': [None],\n",
       " 'max_depth': [None],\n",
       " 'max_leaves': [None],\n",
       " 'min_child_weight': [None],\n",
       " 'missing': [nan],\n",
       " 'monotone_constraints': [None],\n",
       " 'n_estimators': [100],\n",
       " 'n_jobs': [None],\n",
       " 'num_parallel_tree': [None],\n",
       " 'predictor': [None],\n",
       " 'random_state': [None],\n",
       " 'reg_alpha': [None],\n",
       " 'reg_lambda': [None],\n",
       " 'sampling_method': [None],\n",
       " 'scale_pos_weight': [None],\n",
       " 'subsample': [None],\n",
       " 'tree_method': [None],\n",
       " 'validate_parameters': [None],\n",
       " 'verbosity': [None]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params = {}\n",
    "xgbclf = xgb.XGBClassifier()\n",
    "gparams = xgbclf.get_params()\n",
    "\n",
    "#default parameters have to be wrapped in lists - even single values - so GridSearchCV can take them as inputs\n",
    "for key in gparams.keys():\n",
    "    gp = gparams[key]\n",
    "    default_params[key] = [gp]\n",
    "\n",
    "# Create XGBoost DMatrix objects for efficient data handling\n",
    "\n",
    "train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "test = xgb.DMatrix(data=X_test, label=y_test)\n",
    "    \n",
    "#list of hyperparameters available to Tune\n",
    "default_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c737b4-c837-4dc2-b397-adf1d5b1255b",
   "metadata": {},
   "source": [
    "## so which parameters should we tune ?\n",
    "\n",
    "**XG Boost has 4 categories of Hyper parameters\n",
    "\n",
    "- Boosting parameters : controls our SGD / Gradient boosting\n",
    "- Tree parameters : learner decision trees\n",
    "- Stochastic hyperparameters : Subsampling of training  data\n",
    "- Regularization parameter s: model overfitting <br>\n",
    "\n",
    "__[Idea credit Link ](https://link-url-here.org)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328dd5b-ab76-4b44-a510-10f1dd856860",
   "metadata": {},
   "source": [
    "## HyperOpt for hyperparameter search\n",
    "\n",
    "**Why hyperopt:**\n",
    "\n",
    "- Open source\n",
    "- Bayesian optimizer â€“ smart searches over hyperparameters (using a Tree of Parzen Estimators), not grid or random search\n",
    "- Integrates with Apache Spark for parallel hyperparameter search\n",
    "- Integrates with MLflow for automatic tracking of the search results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ae9cfb-5170-4a96-8287-fd2a55e2b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -7, 0),\n",
    "    'max_depth': scope.int(hp.uniform('max_depth', 1, 10)),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -2, 3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'gamma': hp.loguniform('gamma', -10, 10),\n",
    "    'alpha': hp.loguniform('alpha', -10, 10),\n",
    "    'lambda': hp.loguniform('lambda', -10, 10),\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'seed': 123,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "859bbb41-dab5-4136-a0b6-484553541c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With MLflow autologging, hyperparameters and the trained model are automatically logged to MLflow.\n",
    "def train_model(params):\n",
    "    mlflow.xgboost.autolog(silent=True)\n",
    "\n",
    "    # However, we can log additional information by using an MLFlow tracking context manager\n",
    "    with mlflow.start_run(nested=True):\n",
    "\n",
    "        # Train model and record run time\n",
    "        start_time = time.time()\n",
    "        booster = xgb.train(params=params, dtrain=train, num_boost_round=1000, evals=[(test, \"test\")], early_stopping_rounds=50, verbose_eval=False)\n",
    "        run_time = time.time() - start_time\n",
    "        mlflow.log_metric('runtime', run_time)\n",
    "\n",
    "        # Record AUC as primary loss for Hyperopt to minimize\n",
    "        predictions_test = booster.predict(test)\n",
    "        auc_score = roc_auc_score(y_test, predictions_test)\n",
    "        mlflow.log_metric('test-auc', auc_score)\n",
    "\n",
    "        # Set the loss to -1*auc_score so fmin maximizes the auc_score\n",
    "        return {'status': STATUS_OK, 'loss': -auc_score, 'booster': booster.attributes()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29686d4b-217c-49e5-a25d-a4639954e199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/12 07:09:41 INFO mlflow.tracking.fluent: Experiment with name 'HyperParamSearch_V2.0' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9223372036854775807 [13:41<2105013646150214178:08:00, 821.61s/trial, best loss: -0.7148654522808461]\n"
     ]
    }
   ],
   "source": [
    "#spark_trials = SparkTrials(parallelism=4)\n",
    "\n",
    "#http://hyperopt.github.io/hyperopt/scaleout/spark/ Working with SPARK trials\n",
    "\n",
    "# # runs initial search to assess 25 hyperparameter combinations\n",
    "mlflow.set_experiment('HyperParamSearch_V2.0')\n",
    "# with mlflow.start_run(run_name='initial_search'):\n",
    "#     best_params = fmin(\n",
    "#       fn=train_model,\n",
    "#       space=search_space,\n",
    "#       algo=tpe.suggest,\n",
    "#       max_evals=25,\n",
    "#       rstate=np.random.default_rng(123),\n",
    "#       #trials=spark_trials\n",
    "#     )\n",
    "    \n",
    "    \n",
    "# with mlflow.start_run(run_name='xgb_timeout'):\n",
    "#     best_params = fmin(\n",
    "#         fn=train_model,\n",
    "#         space=search_space,\n",
    "#         algo=tpe.suggest,\n",
    "#         timeout=60*10, # stop the grid search after 10 * 60 seconds == 600 minutes\n",
    "#         #trials=spark_trials,\n",
    "#         rstate=np.random.default_rng(123)\n",
    "#     )\n",
    "\n",
    "\n",
    "# This will take a considerable time and computing power to tune. For the purpose of efficiency, we are stopping the run at 10 minutes\n",
    "with mlflow.start_run(run_name='xgb_loss_threshold'):\n",
    "    best_params = fmin(\n",
    "        fn=train_model,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        loss_threshold=-0.7, # stop the grid search once we've reached an AUC of 0.92 or higher\n",
    "        timeout=60*10        # stop after 10 minutes regardless if we reach an AUC of 0.92\n",
    "        #trials=spark_trials,\n",
    "        # rstate=np.random.RandomState(123) # commenting this because for this version of Hyperopt i am geting an error : numpy.random.mtrand.RandomState' object has no attribute 'integers'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e027d56-65f7-4594-ab48-3f3122d83c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0058345912286208905, 'colsample_bytree': 0.7443494456406756, 'gamma': 12.12388434552391, 'lambda': 0.06723169306696562, 'learning_rate': 0.010124899119105817, 'max_depth': 7.146365210529202, 'min_child_weight': 8.07334234933159, 'subsample': 0.6592007721546468}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a64efa7-338e-477e-b8f4-6cb4f5085b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not-cancelled       0.68      0.79      0.73    901401\n",
      "    Cancelled       0.65      0.51      0.57    688758\n",
      "\n",
      "     accuracy                           0.67   1590159\n",
      "    macro avg       0.67      0.65      0.65   1590159\n",
      " weighted avg       0.67      0.67      0.66   1590159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let us check the baseline  base line\n",
    "xgbclf_base = xgb.XGBClassifier()\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"xgbclf_base\", xgbclf_base)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# create classification report\n",
    "y_pred = pipe.predict(X_test)\n",
    "targets = [\"Not-cancelled\", \"Cancelled\"]\n",
    "cls_report = classification_report(y_test, y_pred, target_names=targets)\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66494bd-d971-41d2-bbe7-6f61eaa29bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not-cancelled       0.69      0.78      0.73    901401\n",
      "    Cancelled       0.65      0.53      0.59    688758\n",
      "\n",
      "     accuracy                           0.68   1590159\n",
      "    macro avg       0.67      0.66      0.66   1590159\n",
      " weighted avg       0.67      0.68      0.67   1590159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let us compare the tuned huper parameters from an earlier experiment with the baseline\n",
    "xgbclf_tuned = xgb.XGBClassifier(reg_alpha= 1065.0062093171446, colsample_bytree = 0.9872465841573599, gamma = 0.5541673143204452, reg_lambda = 0.3074638463726531, learning_rate = 0.0756626156028201, max_depth = 47, min_child_weight = 11, subsample =1 )\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"xgbclf_base\", xgbclf_tuned)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# create classification report\n",
    "y_pred = pipe.predict(X_test)\n",
    "targets = [\"Not-cancelled\", \"Cancelled\"]\n",
    "cls_report = classification_report(y_test, y_pred, target_names=targets)\n",
    "print(cls_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
